{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from open ai cookbook:\n",
    "# https://cookbook.openai.com/examples/assistants_api_overview_python\n",
    "\n",
    "# inits\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - create an assistant with file search enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"Machine learning researcher\",\n",
    "    instructions = \"You are a machine learning researcher. Answer questions using the research paper.\",\n",
    "    tools = [{\"type\": \"file_search\"}],\n",
    "    model = \"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Upload files and add them to a Vector Store\n",
    "# https://platform.openai.com/docs/assistants/tools/file-search/step-2-upload-files-and-add-them-to-a-vector-store\n",
    "\n",
    "vector_store = client.beta.vector_stores.create(name=\"memgpt_research\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"memgpt-paper.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)\n",
    "\n",
    "# file = client.files.create(\n",
    "#     file=open(\"memgpt-paper.pdf\", \"rb\"),\n",
    "#     purpose = \"assistants\"\n",
    "# )\n",
    "# print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Update the assistant to use the new Vector Store\n",
    "# To make the files accessible to your assistant, update the assistantâ€™s tool_resources with the new vector_store id.\n",
    "\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_pasJD1F2G6LV3t4mCNTJUd9j', created_at=1719962089, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "# step 4 - create a thread\n",
    "\n",
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"memgpt-paper.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Summarize the research paper\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(thread.tool_resources.file_search)\n",
    "\n",
    "# thread = client.beta.threads.create()\n",
    "# print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5: Crate a run and check the output (without streaming)\n",
    "\n",
    "# Use the create and poll SDK helper to create a run and poll the status of\n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(id='msg_kvEE0nScP7HTprfukeRc7VLy', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Who are the authors of the paper?'), type='text')], created_at=1719962106, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_pasJD1F2G6LV3t4mCNTJUd9j')\n"
     ]
    }
   ],
   "source": [
    "# #step 3 - add a message to the thread\n",
    "# message = client.beta.threads.messages.create(\n",
    "#     thread_id = thread.id,\n",
    "#     role = \"user\",\n",
    "#     content = \"Who are the authors of the paper?\"\n",
    "# )\n",
    "# print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_JQYNDRavMVbxueKsxuN2m3Jx', assistant_id='asst_7MBFhRnx2cqDuvXWygARr8Ip', cancelled_at=None, completed_at=None, created_at=1719962111, expires_at=1719962711, failed_at=None, incomplete_details=None, instructions='You are a machine learning researcher. Answer questions using the research paper.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_pasJD1F2G6LV3t4mCNTJUd9j', tool_choice='auto', tools=[FileSearchTool(type='file_search', file_search=None)], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "#step 4 - run the assistant\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id\n",
    ")\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_JQYNDRavMVbxueKsxuN2m3Jx', assistant_id='asst_7MBFhRnx2cqDuvXWygARr8Ip', cancelled_at=None, completed_at=1719962113, created_at=1719962111, expires_at=None, failed_at=None, incomplete_details=None, instructions='You are a machine learning researcher. Answer questions using the research paper.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1719962111, status='completed', thread_id='thread_pasJD1F2G6LV3t4mCNTJUd9j', tool_choice='auto', tools=[FileSearchTool(type='file_search', file_search=None)], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=33, prompt_tokens=1245, total_tokens=1278), temperature=1.0, top_p=1.0, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "#step 5 - display the assistant's response\n",
    "run = client.beta.threads.runs.retrieve(\n",
    "    thread_id = thread.id, \n",
    "    run_id = run.id\n",
    ")\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_ezrxxkFVHA86UNaefw1wyvFx', assistant_id='asst_7MBFhRnx2cqDuvXWygARr8Ip', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Please upload the research paper, and I'll be happy to help you find the information you need.\"), type='text')], created_at=1719962113, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_JQYNDRavMVbxueKsxuN2m3Jx', status=None, thread_id='thread_pasJD1F2G6LV3t4mCNTJUd9j'), Message(id='msg_kvEE0nScP7HTprfukeRc7VLy', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Who are the authors of the paper?'), type='text')], created_at=1719962106, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_pasJD1F2G6LV3t4mCNTJUd9j')], object='list', first_id='msg_ezrxxkFVHA86UNaefw1wyvFx', last_id='msg_kvEE0nScP7HTprfukeRc7VLy', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id\n",
    ")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Who are the authors of the paper?\n",
      "assistant: Please upload the research paper, and I'll be happy to help you find the information you need.\n"
     ]
    }
   ],
   "source": [
    "for message in reversed(messages.data): \n",
    "    print(message.role + \": \" + message.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
